---
output:
  html_document:
    variant: markdown_github
    keep_md: true
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  fig.align = "center",
  fig.retina = 2,
  out.width = "75%",
  dpi = 96
)
knit_hooks$set(pngquant = hook_pngquant)
```

# sparseEigen

Computation of sparse eigenvectors of a matrix (aka sparse PCA)
    with running time 2-3 orders of magnitude lower than existing methods and
    better final performance in terms of recovery of sparsity pattern and 
    estimation of numerical values. 
    
Can handle covariance matrices as well as data matrices with real or 
    complex-valued entries. Different levels of sparsity can be specified 
    for each individual ordered eigenvector and the method is robust in 
    parameter selection. See vignette for a detailed documentation and 
    comparison, with several illustrative examples. 
    
The package is based on the paper:
    K. Benidis, Y. Sun, P. Babu, and D. P. Palomar (2016), "Orthogonal Sparse PCA 
    and Covariance Estimation via Procrustes Reformulation," IEEE Transactions on 
    Signal Processing, <https://doi.org/10.1109/TSP.2016.2605073>.


## Installation
```{r, eval = FALSE}
# Installation from CRAN
install.packages("sparseEigen")

# Installation from GitHub
# install.packages("devtools")
devtools::install_github("dppalomar/sparseEigen")

# Getting help
library(sparseEigen)
help(package = "sparseEigen")
package?sparseEigen
?spEigen

# Citing this work
citation("sparseEigen")
```

## Vignette
For more detailed information, please check the vignette: [GitHub-html-vignette](https://rawgit.com/dppalomar/sparseEigen/master/vignettes/SparseEigenvectors.html), [GitHub-pdf-vignette](https://rawgit.com/dppalomar/sparseEigen/master/vignettes/SparseEigenvectors.pdf),
[CRAN-pdf-vignette](https://cran.r-project.org/web/packages/sparseEigen/vignettes/SparseEigenvectors.pdf).

## Usage of `spEigen()`
We start by loading the package and generating synthetic data with sparse eigenvectors:
```{r}
library(sparseEigen)
set.seed(42)

# parameters 
m <- 500  # dimension
n <- 100  # number of samples
q <- 3  # number of sparse eigenvectors to be estimated
sp_card <- 0.1*m  # cardinality of each sparse eigenvector

# generate non-overlapping sparse eigenvectors
V <- matrix(0, m, q)
V[cbind(seq(1, q*sp_card), rep(1:q, each = sp_card))] <- 1/sqrt(sp_card)
V <- cbind(V, matrix(rnorm(m*(m-q)), m, m-q))
# keep first q eigenvectors the same (already orthogonal) and orthogonalize the rest
V <- qr.Q(qr(V))  

# generate eigenvalues
lmd <- c(100*seq(from = q, to = 1), rep(1, m-q))

# generate covariance matrix from sparse eigenvectors and eigenvalues
R <- V %*% diag(lmd) %*% t(V)

# generate data matrix from a zero-mean multivariate Gaussian distribution 
# with the constructed covariance matrix
X <- MASS::mvrnorm(n, rep(0, m), R)  # random data with underlying sparse structure
```
Then, we estimate the covariance matrix with `cov(X)` and compute its sparse eigenvectors:
```{r, cache = TRUE}
# computation of sparse eigenvectors
res_standard <- eigen(cov(X))
res_sparse <- spEigen(cov(X), q)
```

We can assess how good the estimated eigenvectors are by computing the inner product with the original eigenvectors (the closer to 1 the better):
```{r}
# show inner product between estimated eigenvectors and originals
abs(diag(t(res_standard$vectors) %*% V[, 1:q]))  #for standard estimated eigenvectors
abs(diag(t(res_sparse$vectors) %*% V[, 1:q]))    #for sparse estimated eigenvectors
```

Finally, the following plot shows the sparsity pattern of the eigenvectors (sparse computation vs. classical computation):
```{r, echo = FALSE, fig.width = 7, fig.height = 7, pngquant = "--speed=1"}
par(mfcol = c(3, 2))
plot(res_sparse$vectors[, 1]*sign(res_sparse$vectors[1, 1]), 
     main = "First sparse eigenvector", xlab = "index", ylab = "", type = "h")
lines(V[, 1]*sign(V[1, 1]), col = "red")
plot(res_sparse$vectors[, 2]*sign(res_sparse$vectors[sp_card+1, 2]), 
     main = "Second sparse eigenvector", xlab = "index", ylab = "", type = "h")
lines(V[, 2]*sign(V[sp_card+1, 2]), col = "red")
plot(res_sparse$vectors[, 3]*sign(res_sparse$vectors[2*sp_card+1, 3]), 
     main = "Third sparse eigenvector", xlab = "index", ylab = "", type = "h")
lines(V[, 3]*sign(V[2*sp_card+1, 3]), col = "red")

plot(res_standard$vectors[, 1]*sign(res_standard$vectors[1, 1]), 
     main = "First regular eigenvector", xlab = "index", ylab = "", type = "h")
lines(V[, 1]*sign(V[1, 1]), col = "red")
plot(res_standard$vectors[, 2]*sign(res_standard$vectors[sp_card+1, 2]), 
     main = "Second regular eigenvector", xlab = "index", ylab = "", type = "h")
lines(V[, 2]*sign(V[sp_card+1, 2]), col = "red")
plot(res_standard$vectors[, 3]*sign(res_standard$vectors[2*sp_card+1, 3]), 
     main = "Third regular eigenvector", xlab = "index", ylab = "", type = "h")
lines(V[, 3]*sign(V[2*sp_card+1, 3]), col = "red")
```

## Usage of `spEigenCov()`

The function `spEigenCov()` requires more samples than the dimension (otherwise some regularization is required). Therefore, we generate data as previously with the only difference that we set the number of samples to be `n=600`.

```{r, echo = FALSE}
n <- 600  # number of samples
X <- MASS::mvrnorm(n, rep(0, m), R)  # random data with underlying sparse structure
```

Then, we compute the covariance matrix through the joint estimation of sparse eigenvectors and eigenvalues:
```{r}
# computation of covariance matrix
res_sparse2 <- spEigenCov(cov(X), q)
```

Again, we can assess how good the estimated eigenvectors are by computing the inner product with the original eigenvectors:
```{r}
# show inner product between estimated eigenvectors and originals
abs(diag(t(res_sparse2$vectors[, 1:q]) %*% V[, 1:q]))    #for sparse estimated eigenvectors
```

Finally, we can compute the error of the estimated covariance matrix (sparse eigenvector computation vs. classical computation):
```{r}
# show error between estimated and true covariance 
norm(cov(X) - R, type = 'F') #for sample covariance matrix
norm(res_sparse2$cov - R, type = 'F') #for covariance with sparse eigenvectors
```

## Links
Package: [CRAN](https://CRAN.R-project.org/package=sparseEigen) and [GitHub](https://github.com/dppalomar/sparseEigen).

README file: [GitHub-readme](https://rawgit.com/dppalomar/sparseEigen/master/README.html) and [CRAN-readme](https://cran.r-project.org/web/packages/sparseEigen/README.html).

Vignette: [GitHub-html-vignette](https://rawgit.com/dppalomar/sparseEigen/master/vignettes/SparseEigenvectors.html), [GitHub-pdf-vignette](https://rawgit.com/dppalomar/sparseEigen/master/vignettes/SparseEigenvectors.pdf),
[CRAN-pdf-vignette](https://cran.r-project.org/web/packages/sparseEigen/vignettes/SparseEigenvectors.pdf).
